{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56d85a0-779b-467a-b521-6a2a7074436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import face_recognition\n",
    "import os\n",
    "import supervision as sv\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLOv10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efacdb8a-8d85-44d7-a499-828efabde7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\Code-for-my-Courses-GABER-main\\\\child detection in car'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32462582-39ee-41c7-972a-e28776de08e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\Code-for-my-Courses-GABER-main\\attendace sytem\n"
     ]
    }
   ],
   "source": [
    "cd \"H:\\Code-for-my-Courses-GABER-main\\attendace sytem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6faddcfa-4147-47b7-8010-5c90eddcec8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\Code-for-my-Courses-GABER-main\\\\attendace sytem'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80ef5ea-6eaf-4984-8776-614237b0c998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive H is gaber\n",
      " Volume Serial Number is 52D0-1D8A\n",
      "\n",
      " Directory of H:\\Code-for-my-Courses-GABER-main\\attendace sytem\n",
      "\n",
      "10/02/2024  02:17 AM    <DIR>          .\n",
      "10/02/2024  02:17 AM    <DIR>          ..\n",
      "07/08/2024  12:27 PM    <DIR>          .ipynb_checkpoints\n",
      "07/08/2024  06:01 PM            47,253 Ahmed Gaber.jpeg\n",
      "10/01/2024  02:20 PM                47 Attendance.csv\n",
      "10/01/2024  01:50 PM    <DIR>          AttendanceImages\n",
      "10/06/2024  02:29 PM                94 attendce_rec.csv\n",
      "07/06/2024  11:49 PM         5,760,164 fakeVSreal.pt\n",
      "07/08/2024  06:05 PM            56,348 Mohammed Gaber.JPG\n",
      "07/12/2024  04:57 AM               617 Untitled.ipynb\n",
      "07/08/2024  11:53 AM    <DIR>          yolov10\n",
      "               6 File(s)      5,864,523 bytes\n",
      "               5 Dir(s)  52,099,264,512 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4e9782-43bd-4b2e-9081-faf22d4159ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ahmed Gaber.JPG', 'Mohammed Gaber.JPG']\n"
     ]
    }
   ],
   "source": [
    "path = 'AttendanceImages'\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17caf710-fc52-4b15-a93d-c40902b60eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ahmed Gaber', 'Mohammed Gaber']\n"
     ]
    }
   ],
   "source": [
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35ebfbe-a8f4-436b-939b-dc5ec6816ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "626f41ae-fb4f-47ea-9f43-aab3a407e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=([\"Present name\",\"Attendance time\",\"Absent name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "215018b6-dfb9-4834-9d36-ca37590d56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"attendce_rec.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d034bd1b-050f-46de-a724-92bc9bdb5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Complete\n"
     ]
    }
   ],
   "source": [
    "def markAttendance(name):\n",
    "    df = pd.read_csv(\"attendce_rec.csv\")\n",
    "    names=[]\n",
    "    [names.append(n.upper())for n in classNames]\n",
    "    absent_names=[]\n",
    "    # Check if the name is already in the DataFrame\n",
    "    if name not in df[\"Present name\"].values:\n",
    "        \n",
    "        names.remove(name)\n",
    "        now = datetime.now()\n",
    "        # Create a new row by passing values as lists\n",
    "        new_row = pd.DataFrame({\"Present name\": [name], \"Attendance time\": [now.strftime(\"%d/%m/%Y %H:%M:%S\")]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        \n",
    "    \n",
    "    # Create a new row for \"Absent name\"\n",
    "    [ absent_names.append(nam) for nam in names if nam not in df[\"Absent name\"].values and nam not in df[\"Present name\"].values ]\n",
    "    new_row = pd.DataFrame({\"Absent name\": absent_names})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_csv(\"attendce_rec.csv\", index=False)\n",
    "\n",
    "# Example usage\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding Complete')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f38205-003f-442a-ba25-0b2b09ce5488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 334.2ms\n",
      "Speed: 20.9ms preprocess, 334.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 302.0ms\n",
      "Speed: 3.5ms preprocess, 302.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 294.7ms\n",
      "Speed: 2.0ms preprocess, 294.7ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 303.1ms\n",
      "Speed: 0.0ms preprocess, 303.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 304.5ms\n",
      "Speed: 5.8ms preprocess, 304.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 294.4ms\n",
      "Speed: 4.1ms preprocess, 294.4ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 301.5ms\n",
      "Speed: 0.0ms preprocess, 301.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 302.7ms\n",
      "Speed: 1.5ms preprocess, 302.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 293.9ms\n",
      "Speed: 9.4ms preprocess, 293.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 296.0ms\n",
      "Speed: 4.6ms preprocess, 296.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 295.5ms\n",
      "Speed: 2.0ms preprocess, 295.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 316.1ms\n",
      "Speed: 2.0ms preprocess, 316.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 300.2ms\n",
      "Speed: 4.7ms preprocess, 300.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 308.8ms\n",
      "Speed: 4.3ms preprocess, 308.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 295.0ms\n",
      "Speed: 5.6ms preprocess, 295.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 296.3ms\n",
      "Speed: 8.1ms preprocess, 296.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 285.3ms\n",
      "Speed: 4.1ms preprocess, 285.3ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 294.1ms\n",
      "Speed: 3.3ms preprocess, 294.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 (no detections), 298.1ms\n",
      "Speed: 5.0ms preprocess, 298.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No classes detected.\n",
      "\n",
      "0: 480x640 1 real, 296.4ms\n",
      "Speed: 3.5ms preprocess, 296.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 real, 269.6ms\n",
      "Speed: 3.7ms preprocess, 269.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 real, 273.7ms\n",
      "Speed: 0.0ms preprocess, 273.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 real, 277.3ms\n",
      "Speed: 4.6ms preprocess, 277.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 real, 262.0ms\n",
      "Speed: 3.7ms preprocess, 262.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 real, 270.3ms\n",
      "Speed: 0.0ms preprocess, 270.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 real, 253.1ms\n",
      "Speed: 3.8ms preprocess, 253.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 real, 256.8ms\n",
      "Speed: 4.1ms preprocess, 256.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "# Assuming YOLOv10, sv.BoundingBoxAnnotator, sv.LabelAnnotator, and other dependencies are already defined/imported\n",
    "\n",
    "model = YOLOv10('fakeVSreal.pt')\n",
    "\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_resizing = 0.25\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    results = model(img, conf=0.75)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "\n",
    "    if results.boxes.cls.numel() == 0:\n",
    "        print(\"No classes detected.\")\n",
    "    else:\n",
    "        # Flags to check presence of both classes\n",
    "        real_detected = (results.boxes.cls == 1).any()\n",
    "        fake_detected = (results.boxes.cls == 0).any()\n",
    "        \n",
    "        if real_detected:\n",
    "            imgS = cv2.resize(img, (0, 0), fx=frame_resizing, fy=frame_resizing)\n",
    "            imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            facesCurFrame = face_recognition.face_locations(imgS)\n",
    "            encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "            \n",
    "            for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "                matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "                faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "                matchIndex = np.argmin(faceDis)\n",
    "                if matches[matchIndex]:\n",
    "                    name = classNames[matchIndex].upper()\n",
    "                    faceLoc = np.array(faceLoc)\n",
    "                    faceLoc = faceLoc / frame_resizing\n",
    "                    faceLoc = faceLoc.astype(int)                    \n",
    "                    y1, x2, y2, x1 = faceLoc[0], faceLoc[1], faceLoc[2], faceLoc[3]\n",
    "                    cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "                    cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "                    markAttendance(name)\n",
    "\n",
    "        if fake_detected :\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "            annotated_image = bounding_box_annotator.annotate(\n",
    "                scene=img, detections=detections)\n",
    "            annotated_image = label_annotator.annotate(\n",
    "                scene=annotated_image, detections=detections ,)\n",
    "            img = annotated_image\n",
    "    \n",
    "    cv2.imshow('Webcam', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3998b2a-3a83-4e3d-a827-92ed04a4efce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
